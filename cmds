# start riffusion server
CUDA_VISIBLE_DEVICES=1 python -m riffusion.server --host 127.0.0.1 --port 8080

# run riffusion inference
curl -X POST http://127.0.0.1:8080/run_inference/ -H "Content-Type: application/json" -d '{"start":{"prompt":"","seed":42,"denoising":0.75,"guidance":7.0},"end":{"prompt":"","seed":123,"denoising":0.75,"guidance":7.0},"alpha":0.5,"num_inference_steps":50,"seed_image_id":"mask_beat_lines_80"}'

# run riffusion inference simple
curl -X POST http://127.0.0.1:8080/run_inference/ -H "Content-Type: application/json" -d '{"start":{"prompt":"","seed":42,"denoising":0.75,"guidance":7.0},"num_inference_steps":50,"seed_image_id":"mask_beat_lines_80"}'

# base64 decode (w/ riffusion output json file)
python3 decode_audio_from_base64.py --json_file_path   --output_wav_path ../results/riffusion_test/

# dataset paths
/mnt/gestalt/home/ytsrt/EGDB-Large-Subset

/mnt/gestalt/home/ytsrt/reaMIXed

# run styleid inference on vocal to EGDB
CUDA_VISIBLE_DEVICES=1 python3 styleid_inference.py --content_audio /mnt/gestalt/home/mku666/wah_emulation/EGDB_DI/233.wav --style_audio /mnt/gestalt/home/mku666/vocal2guitar/vocals/233_sinsy.wav --output_path ./output.wav --prompt_start "" --prompt_end ""

# run styleid inference on MusicTI dataset
CUDA_VISIBLE_DEVICES=1 python3 styleid_inference.py --content_audio /mnt/gestalt/home/mku666/musicTI_audios/content/piano/piano1.wav --style_audio /mnt/gestalt/home/mku666/musicTI_audios/timbre/accordion/accordion1.wav --output_path ./results/musicTI_piano_accordion_test.wav --prompt_start "" --prompt_end ""

# visualize patch embedding overlaying on attention heatmap of riffusion
CUDA_VISIBLE_DEVICES=1 python3 riffusion_heatmap_patch_visualiztion.py --audio_path /mnt/gestalt/home/mku666/musicTI_audios/content/piano/piano1.wav --time_step 5 --attention_layer 6 --query_token 33 --num_inference_steps 30

# visualize attention heatmap of riffusion
python riffusion_activation_visualization.py \
    --audio_path /mnt/gestalt/home/mku666/musicTI_audios/content/piano/piano1.wav \
    --time_step 20 \
    --attention_layer "6,7,8,9,10,11" \
    --head 0 \
    --prompt "electronic beats" \
    --num_inference_steps 30 \
    --seed 42

# stable audio runs
CUDA_VISIBLE_DEVICES=0 python styleid_inference_stableaudio.py     --content_audio /mnt/gestalt/home/mku666/musicTI_audios/content/piano/piano1.wav     --style_audio  /mnt/gestalt/home/mku666/musicTI_audios/timbre/accordion/accordion1.wav     --output_path ./results/piano_in_guitar_style.wav     --gamma 0.7     --T 1.3     --num_inference_steps 50