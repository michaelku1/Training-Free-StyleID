{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# cd to project root\n",
        "%cd /content/drive/MyDrive/riffusion\n",
        "\n",
        "# install environment\n",
        "!curl -L https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh -o miniconda.sh\n",
        "!chmod +x miniconda.sh\n",
        "!sh miniconda.sh -b -p /content/miniconda\n",
        "!/content/miniconda/bin/pip install -r requirements.txt\n",
        "!/content/miniconda/bin/pip install --upgrade ipython ipykernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zCHSse7N_WVa",
        "outputId": "d564f844-621b-4318-d610-54d7752ae797"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/riffusion'\n",
            "/content\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 73.0M  100 73.0M    0     0   103M      0 --:--:-- --:--:-- --:--:--  103M\n",
            "PREFIX=/content/miniconda\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /content/miniconda\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - _openmp_mutex==4.5=1_gnu\n",
            "    - brotlipy==0.7.0=py39h27cfd23_1003\n",
            "    - ca-certificates==2022.3.29=h06a4308_1\n",
            "    - certifi==2021.10.8=py39h06a4308_2\n",
            "    - cffi==1.15.0=py39hd667e15_1\n",
            "    - charset-normalizer==2.0.4=pyhd3eb1b0_0\n",
            "    - colorama==0.4.4=pyhd3eb1b0_0\n",
            "    - conda-content-trust==0.1.1=pyhd3eb1b0_0\n",
            "    - conda-package-handling==1.8.1=py39h7f8727e_0\n",
            "    - conda==4.12.0=py39h06a4308_0\n",
            "    - cryptography==36.0.0=py39h9ce1e76_0\n",
            "    - idna==3.3=pyhd3eb1b0_0\n",
            "    - ld_impl_linux-64==2.35.1=h7274673_9\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.3.0=h5101ec6_17\n",
            "    - libgomp==9.3.0=h5101ec6_17\n",
            "    - libstdcxx-ng==9.3.0=hd4cf53a_17\n",
            "    - ncurses==6.3=h7f8727e_2\n",
            "    - openssl==1.1.1n=h7f8727e_0\n",
            "    - pip==21.2.4=py39h06a4308_0\n",
            "    - pycosat==0.6.3=py39h27cfd23_0\n",
            "    - pycparser==2.21=pyhd3eb1b0_0\n",
            "    - pyopenssl==22.0.0=pyhd3eb1b0_0\n",
            "    - pysocks==1.7.1=py39h06a4308_0\n",
            "    - python==3.9.12=h12debd9_0\n",
            "    - readline==8.1.2=h7f8727e_1\n",
            "    - requests==2.27.1=pyhd3eb1b0_0\n",
            "    - ruamel_yaml==0.15.100=py39h27cfd23_0\n",
            "    - setuptools==61.2.0=py39h06a4308_0\n",
            "    - six==1.16.0=pyhd3eb1b0_1\n",
            "    - sqlite==3.38.2=hc218d9a_0\n",
            "    - tk==8.6.11=h1ccaba5_0\n",
            "    - tqdm==4.63.0=pyhd3eb1b0_0\n",
            "    - tzdata==2022a=hda174b7_0\n",
            "    - urllib3==1.26.8=pyhd3eb1b0_0\n",
            "    - wheel==0.37.1=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.12=h7f8727e_1\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py39h27cfd23_1003\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2022.3.29-h06a4308_1\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.10.8-py39h06a4308_2\n",
            "  cffi               pkgs/main/linux-64::cffi-1.15.0-py39hd667e15_1\n",
            "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
            "  colorama           pkgs/main/noarch::colorama-0.4.4-pyhd3eb1b0_0\n",
            "  conda              pkgs/main/linux-64::conda-4.12.0-py39h06a4308_0\n",
            "  conda-content-tru~ pkgs/main/noarch::conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.8.1-py39h7f8727e_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-36.0.0-py39h9ce1e76_0\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.3-h7f8727e_2\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1n-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.4-py39h06a4308_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py39h27cfd23_0\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-22.0.0-pyhd3eb1b0_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py39h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.9.12-h12debd9_0\n",
            "  readline           pkgs/main/linux-64::readline-8.1.2-h7f8727e_1\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyhd3eb1b0_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.100-py39h27cfd23_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-61.2.0-py39h06a4308_0\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.38.2-hc218d9a_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.11-h1ccaba5_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.63.0-pyhd3eb1b0_0\n",
            "  tzdata             pkgs/main/noarch::tzdata-2022a-hda174b7_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd3eb1b0_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.12-h7f8727e_1\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /content/miniconda\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n",
            "Collecting ipython\n",
            "  Downloading ipython-8.18.1-py3-none-any.whl (808 kB)\n",
            "\u001b[K     |████████████████████████████████| 808 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting ipykernel\n",
            "  Downloading ipykernel-6.30.1-py3-none-any.whl (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 44.5 MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit<3.1.0,>=3.0.41\n",
            "  Downloading prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
            "\u001b[K     |████████████████████████████████| 391 kB 37.1 MB/s \n",
            "\u001b[?25hCollecting exceptiongroup\n",
            "  Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting decorator\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Collecting pygments>=2.4.0\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.9 MB/s \n",
            "\u001b[?25hCollecting pexpect>4.3\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting stack-data\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting jedi>=0.16\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 48.8 MB/s \n",
            "\u001b[?25hCollecting traitlets>=5\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting jupyter-client>=8.0.0\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 55.6 MB/s \n",
            "\u001b[?25hCollecting packaging>=22\n",
            "  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pyzmq>=25\n",
            "  Downloading pyzmq-27.0.2-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (863 kB)\n",
            "\u001b[K     |████████████████████████████████| 863 kB 40.2 MB/s \n",
            "\u001b[?25hCollecting comm>=0.1.1\n",
            "  Downloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
            "Collecting tornado>=6.2\n",
            "  Downloading tornado-6.5.2-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[K     |████████████████████████████████| 443 kB 61.7 MB/s \n",
            "\u001b[?25hCollecting nest-asyncio>=1.4\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Collecting psutil>=5.7\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[K     |████████████████████████████████| 277 kB 24.5 MB/s \n",
            "\u001b[?25hCollecting jupyter-core!=5.0.*,>=4.12\n",
            "  Downloading jupyter_core-5.8.1-py3-none-any.whl (28 kB)\n",
            "Collecting debugpy>=1.6.5\n",
            "  Downloading debugpy-1.8.16-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 52.2 MB/s \n",
            "\u001b[?25hCollecting parso<0.9.0,>=0.8.4\n",
            "  Downloading parso-0.8.5-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 60.6 MB/s \n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[K     |████████████████████████████████| 229 kB 59.8 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata>=4.8.3\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting zipp>=3.20\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Collecting platformdirs>=2.5\n",
            "  Downloading platformdirs-4.4.0-py3-none-any.whl (18 kB)\n",
            "Collecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./miniconda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.16.0)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Installing collected packages: zipp, wcwidth, typing-extensions, traitlets, pure-eval, ptyprocess, platformdirs, parso, executing, asttokens, tornado, stack-data, pyzmq, python-dateutil, pygments, prompt-toolkit, pexpect, matplotlib-inline, jupyter-core, jedi, importlib-metadata, exceptiongroup, decorator, psutil, packaging, nest-asyncio, jupyter-client, ipython, debugpy, comm, ipykernel\n",
            "Successfully installed asttokens-3.0.0 comm-0.2.3 debugpy-1.8.16 decorator-5.2.1 exceptiongroup-1.3.0 executing-2.2.1 importlib-metadata-8.7.0 ipykernel-6.30.1 ipython-8.18.1 jedi-0.19.2 jupyter-client-8.6.3 jupyter-core-5.8.1 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 packaging-25.0 parso-0.8.5 pexpect-4.9.0 platformdirs-4.4.0 prompt-toolkit-3.0.52 psutil-7.0.0 ptyprocess-0.7.0 pure-eval-0.2.3 pygments-2.19.2 python-dateutil-2.9.0.post0 pyzmq-27.0.2 stack-data-0.6.3 tornado-6.5.2 traitlets-5.14.3 typing-extensions-4.15.0 wcwidth-0.2.13 zipp-3.23.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install additional dependencies\n",
        "! pip install dacite flask_cors flask_ngrok pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MCDHSnk8_e4N",
        "outputId": "48d4999c-b6d2-44b9-8834-a1d8c331bed0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dacite\n",
            "  Downloading dacite-1.9.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting flask_cors\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: flask>=0.9 in /usr/local/lib/python3.12/dist-packages (from flask_cors) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.12/dist-packages (from flask_cors) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from flask_ngrok) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask_cors) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask_cors) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask_cors) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask_cors) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask_cors) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->flask_ngrok) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->flask_ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->flask_ngrok) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->flask_ngrok) (2025.8.3)\n",
            "Downloading dacite-1.9.2-py3-none-any.whl (16 kB)\n",
            "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok, dacite, flask_ngrok, flask_cors\n",
            "Successfully installed dacite-1.9.2 flask_cors-6.0.1 flask_ngrok-0.0.25 pyngrok-7.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# where script saved under\n",
        "%cd /content/drive/MyDrive/Training-Free-StyleID"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiEohULoAZ21",
        "outputId": "d78a1ec7-a1aa-4187-b10e-014cfea6f46f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Training-Free-StyleID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Flask server that serves the riffusion model as an API.\n",
        "\"\"\"\n",
        "\n",
        "import dataclasses\n",
        "import io\n",
        "import json\n",
        "import logging\n",
        "import time\n",
        "import typing as T\n",
        "from pathlib import Path\n",
        "\n",
        "import dacite\n",
        "import flask\n",
        "import PIL\n",
        "import torch\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Fix CUDA linear algebra backend to avoid cusolver errors\n",
        "torch.backends.cuda.preferred_linalg_library('magma')\n",
        "\n",
        "# NOTE original riffusion pipeline\n",
        "from riffusion.riffusion_pipeline import RiffusionPipeline\n",
        "from riffusion.datatypes import InferenceInput, InferenceOutput\n",
        "\n",
        "from riffusion.spectrogram_image_converter import SpectrogramImageConverter\n",
        "from riffusion.spectrogram_params import SpectrogramParams\n",
        "\n",
        "# from flask_ngrok import run_with_ngrok\n",
        "NGROK_AUTH_TOKEN = \"32MmrpMI4sZN558sIugyRuhDgDg_5AdY64F9xihYgNZZfyHJL\"\n",
        "\n",
        "# Flask app with CORS\n",
        "app = flask.Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "\n",
        "# Create a logger object\n",
        "logger = logging.getLogger(\"my_server\")\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# Log at the INFO level to both stdout and disk\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.FileHandler(\"server.log\"))\n",
        "\n",
        "# Create a file handler to write logs to a file\n",
        "file_handler = logging.FileHandler(\"server.log\")\n",
        "file_handler.setLevel(logging.DEBUG)\n",
        "\n",
        "# set format\n",
        "formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')\n",
        "\n",
        "# initalise file handler\n",
        "file_handler.setFormatter(formatter)\n",
        "\n",
        "# initalise console handler\n",
        "console_handler = logging.StreamHandler()\n",
        "console_handler.setLevel(logging.INFO)\n",
        "console_handler.setFormatter(formatter)\n",
        "\n",
        "# Add handlers to the logger\n",
        "logger.addHandler(file_handler)\n",
        "\n",
        "# Global variable for the model pipeline\n",
        "PIPELINE: T.Optional[RiffusionPipeline] = None\n",
        "\n",
        "# set auth token for free n_grok usage\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "odngfjdy-fjU",
        "outputId": "3717e256-f897-48e2-ff64-08f38def3882"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_request(\n",
        "    inputs: InferenceInput,\n",
        "    pipeline: RiffusionPipeline,\n",
        ") -> T.Union[str, T.Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Does all the heavy lifting of the request.\n",
        "\n",
        "    Args:\n",
        "        inputs: The input dataclass\n",
        "        pipeline: The riffusion model pipeline\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the seed image by ID\n",
        "    init_image_path = Path(f\"{inputs.seed_image_path}.png\")\n",
        "\n",
        "    print(\"######################### input image path: \", init_image_path)\n",
        "\n",
        "    if not init_image_path.is_file():\n",
        "        return f\"Invalid seed image: {inputs.seed_image_path}\", 400\n",
        "    init_image = PIL.Image.open(str(init_image_path)).convert(\"RGB\")\n",
        "\n",
        "    # Load the mask image by ID\n",
        "    mask_image: T.Optional[PIL.Image.Image] = None\n",
        "\n",
        "    # NOTE pass mask image here\n",
        "    # mask_image = PIL.Image.open(\"...png\").convert(\"RGB\")\n",
        "    if inputs.mask_image_path:\n",
        "        mask_image_path = Path(f\"{inputs.mask_image_path}.png\")\n",
        "        if not mask_image_path.is_file():\n",
        "            return f\"Invalid mask image: {inputs.mask_image_path}\", 400\n",
        "        mask_image = PIL.Image.open(str(mask_image_path)).convert(\"RGB\")\n",
        "\n",
        "    # Execute the model to get the spectrogram image\n",
        "    image = pipeline.riffuse(\n",
        "        inputs,\n",
        "        init_image=init_image,\n",
        "        mask_image=mask_image,\n",
        "    )\n",
        "\n",
        "    # TODO(hayk): Change the frequency range to [20, 20k] once the model is retrained\n",
        "    params = SpectrogramParams(\n",
        "        min_frequency=0,\n",
        "        max_frequency=10000,\n",
        "    )\n",
        "\n",
        "    # Reconstruct audio from the image\n",
        "    # TODO(hayk): It may help performance a bit to cache this object\n",
        "    # Use CPU for audio processing to avoid CUDA solver issues\n",
        "    converter = SpectrogramImageConverter(params=params, device=\"cpu\")\n",
        "\n",
        "    # NOTE 轉回 audio signal\n",
        "    segment = converter.audio_from_spectrogram_image(\n",
        "        image,\n",
        "        apply_filters=True,\n",
        "    )\n",
        "\n",
        "    # Export audio to MP3 bytes\n",
        "    mp3_bytes = io.BytesIO()\n",
        "    segment.export(mp3_bytes, format=\"mp3\")\n",
        "    mp3_bytes.seek(0)\n",
        "\n",
        "    # Export image to JPEG bytes\n",
        "    image_bytes = io.BytesIO()\n",
        "    image.save(image_bytes, exif=image.getexif(), format=\"JPEG\")\n",
        "    image_bytes.seek(0)\n",
        "\n",
        "    # Assemble the output dataclass\n",
        "    output = InferenceOutput(\n",
        "        image=\"data:image/jpeg;base64,\" + base64_util.encode(image_bytes),\n",
        "        audio=\"data:audio/mpeg;base64,\" + base64_util.encode(mp3_bytes),\n",
        "        duration_s=segment.duration_seconds,\n",
        "    )\n",
        "\n",
        "    # release memory\n",
        "    import gc\n",
        "    del image, mask_image, init_image  # delete big tensors\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()  # free cached memory\n",
        "    torch.cuda.ipc_collect()  # (optional) reclaim inter-process memory\n",
        "\n",
        "    output_name = f\"{''.join(inputs.seed_image_path.split('/')[-2:])}_to_{''.join(inputs.mask_image_path.split('/')[-2:])}\"\n",
        "\n",
        "    with open(f\"{inputs.output_path}/{output_name}.json\", \"w\") as f:\n",
        "        json.dump(dataclasses.asdict(output), f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "HB1JxDpb_J7m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Where built-in seed images are stored\n",
        "# import traceback\n",
        "# def run_app_background(*args, **kwargs):\n",
        "#     try:\n",
        "#         # Your existing Flask + ngrok code\n",
        "#         global PIPELINE\n",
        "\n",
        "#         import logging, sys\n",
        "#         logging.basicConfig(\n",
        "#             level=logging.DEBUG,\n",
        "#             format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "#             handlers=[logging.StreamHandler(sys.stdout)]\n",
        "#         )\n",
        "#         app.logger.setLevel(logging.DEBUG)\n",
        "\n",
        "#         app.logger.info(\"Loading RiffusionPipeline...\")\n",
        "#         PIPELINE = RiffusionPipeline.load_checkpoint(\n",
        "#             checkpoint=kwargs.get(\"checkpoint\", \"riffusion/riffusion-model-v1\"),\n",
        "#             use_traced_unet=not kwargs.get(\"no_traced_unet\", False),\n",
        "#             device=kwargs.get(\"device\", \"cuda\")\n",
        "#         )\n",
        "#         app.logger.info(\"Pipeline loaded successfully!\")\n",
        "\n",
        "#         public_url = ngrok.connect(kwargs.get(\"port\", 5000))\n",
        "#         print(f\" * ngrok tunnel URL: {public_url}\", flush=True)\n",
        "\n",
        "#         app.logger.info(f\"Starting Flask server on port {kwargs.get('port', 5000)}...\")\n",
        "#         app.run(port=kwargs.get(\"port\", 5000), debug=kwargs.get(\"debug\", True), use_reloader=False)\n",
        "\n",
        "#     except Exception:\n",
        "#         print(\"Exception in background thread:\", flush=True)\n",
        "#         traceback.print_exc()\n",
        "\n",
        "def run_app(\n",
        "    *,\n",
        "    checkpoint: str = \"riffusion/riffusion-model-v1\",\n",
        "    no_traced_unet: bool = False,\n",
        "    device: str = \"cuda\",\n",
        "    port: int = 5000,\n",
        "    debug: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Run a Flask API that serves the given riffusion model checkpoint\n",
        "    and exposes it via ngrok.\n",
        "    \"\"\"\n",
        "    global PIPELINE\n",
        "\n",
        "    # Initialize the model\n",
        "    PIPELINE = RiffusionPipeline.load_checkpoint(\n",
        "        checkpoint=checkpoint,\n",
        "        use_traced_unet=not no_traced_unet,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # Set debug mode\n",
        "    app.debug = debug\n",
        "\n",
        "    # Start ngrok tunnel\n",
        "    public_url = ngrok.connect(port)\n",
        "    print(f\" * ngrok tunnel URL: {public_url}\", flush=True)\n",
        "\n",
        "    # Start Flask server\n",
        "    app.run(port=port)\n",
        "\n",
        "\n",
        "@app.route(\"/run_inference/\", methods=[\"POST\"])\n",
        "def run_inference():\n",
        "    \"\"\"\n",
        "    Execute the riffusion model as an API.\n",
        "\n",
        "    Inputs:\n",
        "        Serialized JSON of the InferenceInput dataclass\n",
        "\n",
        "    Returns:\n",
        "        Serialized JSON of the InferenceOutput dataclass\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Parse the payload as JSON\n",
        "    json_data = json.loads(flask.request.data)\n",
        "\n",
        "    # Log the request\n",
        "    logging.info(json_data)\n",
        "\n",
        "    # Parse an InferenceInput dataclass from the payload\n",
        "    try:\n",
        "        inputs = dacite.from_dict(InferenceInput, json_data)\n",
        "    except dacite.exceptions.WrongTypeError as exception:\n",
        "        logging.info(json_data)\n",
        "        return str(exception), 400\n",
        "    except dacite.exceptions.MissingValueError as exception:\n",
        "        logging.info(json_data)\n",
        "        return str(exception), 400\n",
        "\n",
        "    # NOTE\n",
        "    response = compute_request(\n",
        "        inputs=inputs,\n",
        "        pipeline=PIPELINE,\n",
        "    )\n",
        "\n",
        "    # Log the total time\n",
        "    logging.info(f\"Request took {time.time() - start_time:.2f} s\")\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "# @app.route(\"/run_inference/\", methods=[\"POST\"])\n",
        "# def run_inference():\n",
        "#     \"\"\"\n",
        "#     Execute the riffusion model as an API.\n",
        "\n",
        "#     Inputs:\n",
        "#         Serialized JSON of the InferenceInput dataclass\n",
        "\n",
        "#     Returns:\n",
        "#         Serialized JSON of the InferenceOutput dataclass\n",
        "#     \"\"\"\n",
        "#     start_time = time.time()\n",
        "\n",
        "#     # Parse the payload as JSON\n",
        "#     json_data = json.loads(flask.request.data)\n",
        "\n",
        "#     # Log the request\n",
        "#     logging.info(json_data)\n",
        "\n",
        "#     # Parse an InferenceInput dataclass from the payload\n",
        "#     try:\n",
        "#         inputs = dacite.from_dict(InferenceInput, json_data)\n",
        "#     except dacite.exceptions.WrongTypeError as exception:\n",
        "#         logging.info(json_data)\n",
        "#         return str(exception), 400\n",
        "#     except dacite.exceptions.MissingValueError as exception:\n",
        "#         logging.info(json_data)\n",
        "#         return str(exception), 400\n",
        "\n",
        "#     # NOTE\n",
        "#     response = compute_request(\n",
        "#         inputs=inputs,\n",
        "#         pipeline=PIPELINE,\n",
        "#     )\n",
        "\n",
        "#     # Log the total time\n",
        "#     logging.info(f\"Request took {time.time() - start_time:.2f} s\")\n",
        "\n",
        "#     return response\n",
        "\n",
        "def start_server():\n",
        "  run_app()"
      ],
      "metadata": {
        "id": "yPqYI5-a-Yuk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set to background thread\n",
        "import threading\n",
        "threading.Thread(target=start_server, daemon=True).start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2Il160ltI8o7",
        "outputId": "21e69948-a4f7-4956-a2ab-314283145914"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Falling back to float32 on cpu, float16 is unsupported\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3189065214.py:49: UserWarning: WARNING: cuda is not available, using cpu instead.\n",
            "  PIPELINE = RiffusionPipeline.load_checkpoint(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference\n",
        "CUDA_DEVICE=1\n",
        "START_SEED=42\n",
        "END_SEED=123\n",
        "DENOISING=0.2\n",
        "GUIDANCE=0\n",
        "ALPHA=0\n",
        "STEPS=50\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/riffusion/Training-Free-StyleID/results/audio\"\n",
        "SEED_IMAGE_PATH=\"/content/drive/MyDrive/riffusion/results/riffusion_seed_mask_images/accordian123/1\"\n",
        "MASK_IMAGE_PATH=\"/content/drive/MyDrive/riffusion/results/riffusion_seed_mask_images/violin123/1\"\n",
        "\n",
        "# Run curl command\n",
        "!CUDA_VISIBLE_DEVICES=\"$CUDA_DEVICE\" curl -X POST http://127.0.0.1:5000/run_inference/ -H \"Content-Type: application/json\" -d '{\"start\":{\"prompt\":\"\",\"seed\":'\"$START_SEED\"',\"denoising\":'\"$DENOISING\"',\"guidance\":'\"$GUIDANCE\"'},\"num_inference_steps\":'\"$STEPS\"',\"seed_image_path\":\"'\"$SEED_IMAGE_PATH\"'\",\"mask_image_path\":\"'\"$MASK_IMAGE_PATH\"'\",\"alpha\":'\"$ALPHA\"',\"end\":{\"prompt\":\"\",\"seed\":'\"$END_SEED\"',\"denoising\":'\"$DENOISING\"',\"guidance\":'\"$GUIDANCE\"', \"output_path\": '\"$OUTPUT_PATH\"'}}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tv8mgGuBgLWX",
        "outputId": "07d019cb-018b-4838-ab41-ff6db441946c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: (7) Failed to connect to 127.0.0.1 port 5000 after 0 ms: Connection refused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "data = {\n",
        "    \"start\": {\"prompt\": \"\", \"seed\": START_SEED, \"denoising\": DENOISING, \"guidance\": GUIDANCE},\n",
        "    \"num_inference_steps\": STEPS,\n",
        "    \"seed_image_path\": SEED_IMAGE_PATH,\n",
        "    \"mask_image_path\": MASK_IMAGE_PATH,\n",
        "    \"alpha\": ALPHA,\n",
        "    \"end\": {\"prompt\": \"\", \"seed\": END_SEED, \"denoising\": DENOISING, \"guidance\": GUIDANCE, \"output_path\": OUTPUT_PATH}\n",
        "}\n",
        "\n",
        "response = requests.post(\"http://127.0.0.1:5000/run_inference/\", json=data)\n",
        "try:\n",
        "    response = requests.post(\"http://127.0.0.1:5000/run_inference/\", json=data)\n",
        "    logger.info(f\"Response status code: {response.status_code}\")\n",
        "    logger.info(f\"Response text: {response.text[:500]}\")  # limit output to first 500 chars\n",
        "except Exception as e:\n",
        "    logger.error(f\"Request failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrftbiHlvvt4",
        "outputId": "78e03d7a-d0b9-4c63-dd20-8c271611ee3b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [08/Sep/2025 03:48:53] \"\u001b[31m\u001b[1mPOST /run_inference/ HTTP/1.1\u001b[0m\" 400 -\n",
            "INFO:werkzeug:127.0.0.1 - - [08/Sep/2025 03:48:53] \"\u001b[31m\u001b[1mPOST /run_inference/ HTTP/1.1\u001b[0m\" 400 -\n",
            "INFO:my_server:Response status code: 400\n",
            "INFO:my_server:Response text: Invalid seed image: /content/drive/MyDrive/riffusion/results/riffusion_seed_mask_images/accordian123/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################### input image path:  /content/drive/MyDrive/riffusion/results/riffusion_seed_mask_images/accordian123/1.png\n",
            "######################### input image path:  /content/drive/MyDrive/riffusion/results/riffusion_seed_mask_images/accordian123/1.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "try pyngrok"
      ],
      "metadata": {
        "id": "lyg6bs1CgMvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THI8NHW9gSUq",
        "outputId": "acde4a68-64dd-4786-b82b-ad2916b64161"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import typing as T\n",
        "import logging\n",
        "import time\n",
        "import json\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import dacite\n",
        "\n",
        "app = Flask(__name__)\n",
        "PIPELINE = None  # will be initialized in run_app\n",
        "\n",
        "def run_app(\n",
        "    *,\n",
        "    checkpoint: str = \"riffusion/riffusion-model-v1\",\n",
        "    no_traced_unet: bool = False,\n",
        "    device: str = \"cuda\",\n",
        "    port: int = 5000,\n",
        "    debug: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Run a Flask API that serves the given riffusion model checkpoint\n",
        "    and exposes it via ngrok.\n",
        "    \"\"\"\n",
        "    global PIPELINE\n",
        "\n",
        "    # Initialize the model\n",
        "    PIPELINE = RiffusionPipeline.load_checkpoint(\n",
        "        checkpoint=checkpoint,\n",
        "        use_traced_unet=not no_traced_unet,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # Set debug mode\n",
        "    app.debug = debug\n",
        "\n",
        "    # Start ngrok tunnel\n",
        "    public_url = ngrok.connect(port)\n",
        "    print(f\" * ngrok tunnel URL: {public_url}\")\n",
        "\n",
        "    # Start Flask server\n",
        "    app.run(port=port)\n",
        "\n",
        "def start_server():\n",
        "  run_app()"
      ],
      "metadata": {
        "id": "gb613_tygQHz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "loWPnRcyn1Lt",
        "outputId": "4532d162-52f6-4777-d42f-bff4dd6ac9b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'testing' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4003044685.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'testing' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set to background thread\n",
        "import threading\n",
        "threading.Thread(target=start_server, daemon=True).start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atFteNCiroM5",
        "outputId": "c91b44f5-32a0-4ae3-96d3-8acb56fe6e1f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Falling back to float32 on cpu, float16 is unsupported\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1977693823.py:27: UserWarning: WARNING: cuda is not available, using cpu instead.\n",
            "  PIPELINE = RiffusionPipeline.load_checkpoint(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test run_app() with n_grok setting"
      ],
      "metadata": {
        "id": "unm7QRbZX7yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test app server\n",
        "# from flask import Flask, request, jsonify\n",
        "# from flask_ngrok import run_with_ngrok\n",
        "# import argh\n",
        "\n",
        "# def run_app():\n",
        "#   app = Flask(__name__)\n",
        "#   run_with_ngrok(app)  # starts ngrok when app.run() is called\n",
        "\n",
        "#   @app.route(\"/hello\", methods=[\"GET\"])\n",
        "#   def hello():\n",
        "#       return jsonify({\"msg\": \"Hello from Flask in Colab!\"})\n",
        "\n",
        "#   @app.route(\"/echo\", methods=[\"POST\"])\n",
        "#   def echo():\n",
        "#       data = request.json\n",
        "#       return jsonify({\"you_sent\": data})\n",
        "\n",
        "#   app.run()\n",
        "\n",
        "# this line is the problem\n",
        "# argh.dispatch_command(run_app)"
      ],
      "metadata": {
        "id": "73PLrNKyJ1eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def run_app(\n",
        "#     *,\n",
        "#     checkpoint: str = \"riffusion/riffusion-model-v1\",\n",
        "#     no_traced_unet: bool = False,\n",
        "#     device: str = \"cuda\",\n",
        "#     host: str = \"127.0.0.1\",\n",
        "#     port: int = 8001,\n",
        "#     debug: bool = False,\n",
        "#     ssl_certificate: T.Optional[str] = None,\n",
        "#     ssl_key: T.Optional[str] = None,\n",
        "# ):\n",
        "    \"\"\"\n",
        "    Run a flask API that serves the given riffusion model checkpoint.\n",
        "    \"\"\"\n",
        "    # Initialize the model\n",
        "    # global PIPELINE\n",
        "\n",
        "    # PIPELINE = RiffusionPipeline.load_checkpoint(\n",
        "    #     checkpoint=checkpoint,\n",
        "    #     use_traced_unet=True,\n",
        "    #     device=device,\n",
        "    # )\n",
        "\n",
        "    # TypeError: run_with_ngrok.<locals>.new_run() got an unexpected keyword argument 'debug'\n",
        "    # args = dict(\n",
        "    #     # debug=debug,\n",
        "    #     # threaded=False,\n",
        "    #     host=host,\n",
        "    #     port=port,\n",
        "    # )\n",
        "\n",
        "    # if ssl_certificate:\n",
        "    #     assert ssl_key is not None\n",
        "    #     args[\"ssl_context\"] = (ssl_certificate, ssl_key)\n",
        "\n",
        "    # app.run(**args)  # type: ignore"
      ],
      "metadata": {
        "id": "JxiPqe04X92K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_app() # app.run(**args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "vF6Jkz3YYJPF",
        "outputId": "09516ca5-8ba9-4784-db6a-efbe7633e899"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "run_with_ngrok.<locals>.new_run() got an unexpected keyword argument 'host'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-718536340.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_app\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1491935548.py\u001b[0m in \u001b[0;36mrun_app\u001b[0;34m(checkpoint, no_traced_unet, device, host, port, debug, ssl_certificate, ssl_key)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ssl_context\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mssl_certificate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: run_with_ngrok.<locals>.new_run() got an unexpected keyword argument 'host'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "# Flask app with CORS\n",
        "app = flask.Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# run background thread (with daemon)\n",
        "run_with_ngrok(app)"
      ],
      "metadata": {
        "id": "htTBoWk7YgAW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8kVk9kQvaQ3k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}